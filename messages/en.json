{
    "Common": {
        "loading": "Loading...",
        "error": "Error",
        "status": "Status",
        "paused": "Paused",
        "running": "Running",
        "debugMode": "Debug Mode",
        "off": "Off",
        "token": "Token",
        "tokens": "Tokens",
        "unknown": "Unknown"
    },
    "Toolbar": {
        "enableDebug": "Enable Debug",
        "disableDebug": "Disable Debug",
        "pause": "Pause",
        "resume": "Resume",
        "nextLayer": "Next Layer",
        "nextToken": "Next Token",
        "step": "Step",
        "refresh": "Refresh",
        "clear": "Clear",
        "testStream": "Debug",
        "inputPrompt": "Enter prompt...",
        "testing": "Debugging..."
    },
    "DetailPanel": {
        "title": "Detail Panel",
        "noSelection": "Select a layer or node to view details",
        "layerInfo": "Layer Info",
        "tensorInfo": "Tensor Info",
        "debugInfo": "Debug Info",
        "currentOp": "Current Op",
        "inputs": "Inputs",
        "tensors": "Tensors",
        "architecture": "Architecture",
        "activation": "Activation",
        "posEmb": "Pos Emb",
        "modelConfig": "Model Config",
        "name": "Name",
        "arch": "Arch",
        "layers": "Layers",
        "embdDim": "Embd Dim",
        "heads": "Heads",
        "node": "Node",
        "op": "Op",
        "out": "Out",
        "shape": "Shape",
        "type": "Type",
        "size": "Size"
    },
    "Home": {
        "title": "LLM Inference Debugger",
        "loadingModel": "Loading model info...",
        "pleaseWait": "Please wait",
        "loadFailed": "Failed to load model info",
        "checkBackend": "Please check if backend service is running",
        "generatedTokens": "Generated Tokens",
        "noTokens": "No tokens generated yet",
        "instructions": "Instructions",
        "instruction1": "Enter prompt above and click **Debug** to start",
        "instruction2": "Inference will pause after each token generation",
        "instruction3": "Use **Step** / **Next Token** to advance",
        "instruction4": "Use **Resume** to continue automatic generation",
        "instruction5": ""
    },
    "ModelGraph": {
        "inputTokens": "Input Tokens",
        "tokenEmbedding": "Token Embedding",
        "layerEntry": "Layer Entry",
        "layerExit": "Layer Exit",
        "iterate": "Iterate",
        "finalNorm": "Final Norm",
        "outputProj": "Output Proj (LM Head)",
        "layerTitle": "[ LAYER {index} / {total} ]"
    }
}